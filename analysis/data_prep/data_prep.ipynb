{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "\n",
    "This notebook explores and summarizes environmental and pathogen data for high and medium priority fungal pathogens in Northeastern Thailand. \n",
    "\n",
    "- Loads and processes abundance and metadata for both training and test datasets.\n",
    "- Focuses on high and medium priority pathogens, excluding critical priority due to lack of samples.\n",
    "- Identifies and saves sample IDs associated with each pathogen group. This data is used for training and test the decision tree models\n",
    "- Merges pathogen presence/absence with environmental properties for each sample.\n",
    "- Summarizes the number of samples per class (present/absent) for each pathogen group.\n",
    "- Visualizes data distributions and relationships using pairplots and boxplots for environmental features, grouped by pathogen presence.\n",
    "\n",
    "**Note**: \n",
    "- Results from `match_taxonomy_to_key_names.ipynb` are required to run this notebook\n",
    "- In order to run `analysis/model/automated_decision_tree.ipynb`, you need to run this notebook for both `data_set='training'` and `data_set='test'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "- This analysis focuses on high and medium priority fungal pathogens.\n",
    "- Critical priority pathogens are excluded because the training and test datasets do not contain samples with critical priority pathogens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get path for folders\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"../..\"))\n",
    "\n",
    "# folders\n",
    "data_folder = os.path.join(project_root, \"data\")\n",
    "\n",
    "results_folder = os.path.join(project_root, \"results\")\n",
    "os.makedirs(results_folder, exist_ok=True)\n",
    "\n",
    "group_names_folder = os.path.join(results_folder, \"group_names\")\n",
    "os.makedirs(group_names_folder, exist_ok=True)\n",
    "\n",
    "cross_plots_folder = os.path.join(results_folder, \"cross_plots\")\n",
    "os.makedirs(cross_plots_folder, exist_ok=True)\n",
    "\n",
    "box_plots_folder = os.path.join(results_folder, \"box_plots\")\n",
    "os.makedirs(box_plots_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data set to use\n",
    "data_set = \"test\"  # options: \"training\" or \"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "if data_set == \"training\":\n",
    "    data_df = pd.read_csv(os.path.join(data_folder,\"DroughtITS.final.txt\"), sep = \"\\t\")\n",
    "elif data_set == \"test\":\n",
    "    data_df = pd.read_csv(os.path.join(data_folder,\"SakhonNakhonApril2025.final.txt\"), sep = \"\\t\")\n",
    "else:\n",
    "    raise ValueError(\"Invalid data_set value. Choose 'training' or 'test'.\")   \n",
    "\n",
    "# rename the column\n",
    "data_df = data_df.rename(columns={'#OTU ID': 'SampleID'})\n",
    "\n",
    "# transpose the dataframe \n",
    "data_df = data_df.transpose().reset_index()\n",
    "\n",
    "# rename the column names \n",
    "data_df.columns = data_df.iloc[0]\n",
    "\n",
    "# remove the first row (column names)\n",
    "data_df = data_df[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### High Priority"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_priority_samples_df = pd.read_csv(f\"{data_folder}/high_priority_sample_names_{data_set}_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_priority_names_df = high_priority_samples_df.groupby('classification_group').agg({'Name': set}).reset_index()\n",
    "high_priority_names_df['Name'] = high_priority_names_df['Name'].apply(lambda x: list(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_priority_group_names = high_priority_names_df['classification_group'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for group_name in high_priority_group_names:\n",
    "    names = high_priority_names_df[high_priority_names_df.classification_group == group_name].iloc[0].Name\n",
    "    condition = (data_df[names] > 0).any(axis=1)\n",
    "    filtered_df = data_df[condition]\n",
    "    filtered_df.to_csv(f\"{data_folder}/high_priority/{group_name}_sampleIDs_{data_set}_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save name of the high priority samples\n",
    "with open(f\"{results_folder}/group_names/high_priority_pathogen_group_names_{data_set}_data.txt\", \"w\") as file:\n",
    "    for group_name in high_priority_group_names:\n",
    "        file.write(f\"{group_name}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Medium priority"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "medium_priority_samples_df = pd.read_csv(f\"{data_folder}/medium_priority_sample_names_{data_set}_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "medium_priority_names_df = medium_priority_samples_df.groupby('classification_group').agg({'Name': set}).reset_index()\n",
    "medium_priority_names_df['Name'] = medium_priority_names_df['Name'].apply(lambda x: list(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "medium_priority_group_names = medium_priority_names_df['classification_group'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for group_name in medium_priority_group_names:\n",
    "    names = medium_priority_names_df[medium_priority_names_df.classification_group == group_name].iloc[0].Name\n",
    "    condition = (data_df[names] > 0).any(axis=1)\n",
    "    filtered_df = data_df[condition]\n",
    "    filtered_df.to_csv(f\"{data_folder}/medium_priority/{group_name}_sampleIDs_{data_set}_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save name of the medium priority samples\n",
    "with open(f\"{results_folder}/group_names/medium_priority_pathogen_group_names_{data_set}_data.txt\", \"w\") as file:\n",
    "    for group_name in medium_priority_group_names:\n",
    "        file.write(f\"{group_name}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environmental properties data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_set == 'training':\n",
    "    properties_df = pd.read_csv(os.path.join(data_folder,\"DroughtITS.mapping_file.fix.txt\"), sep = \"\\t\")\n",
    "\n",
    "    # remove unnecessary columns\n",
    "    drop_columns = ['BarcodeSequence', 'LinkerPrimerSequence',\n",
    "       'RevBarcodeSequence', 'ReversePrimer', 'phinchID', 'DemuxReads',\n",
    "       'Treatment']\n",
    "    \n",
    "    properties_df = properties_df.drop(columns=drop_columns)\n",
    "\n",
    "elif data_set == 'test':\n",
    "    properties_df = pd.read_csv(os.path.join(data_folder,\"SakhonNakhonApril2025.mapping_file.txt\"), sep = \"\\t\")\n",
    "\n",
    "    # remove _n and _p from 'plant' column\n",
    "    properties_df['plant'] = properties_df['plant'].str.replace('_n', '')\n",
    "    properties_df['plant'] = properties_df['plant'].str.replace('_p', '')\n",
    "    properties_df['plant'] = properties_df['plant'].str.replace('_', ' ')\n",
    "\n",
    "else:\n",
    "    raise ValueError(\"Invalid data_set value. Choose 'training' or 'test'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_group_names = high_priority_group_names + medium_priority_group_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_possible_group_names = ['Acremonium spp.', 'Candida tropicalis',\n",
    "       'Curvularia lunata', 'Falciformispora senegalensis', 'Fusarium spp.',\n",
    "       'Lichtheimia spp.', 'Mucor spp.', 'Rhizopus spp.', 'Scedosporium spp.',\n",
    "       'Talaromyces marneffei']\n",
    "\n",
    "for group_name in all_possible_group_names:\n",
    "    if group_name in all_group_names:\n",
    "        if group_name in high_priority_group_names:\n",
    "            df = pd.read_csv(f\"{data_folder}/high_priority/{group_name}_sampleIDs_{data_set}_data.csv\")\n",
    "        else:\n",
    "            df = pd.read_csv(f\"{data_folder}/medium_priority/{group_name}_sampleIDs_{data_set}_data.csv\")\n",
    "        if data_set == 'training':\n",
    "            SampleIDs = df['SampleID'].to_list()\n",
    "        elif data_set == 'test':\n",
    "            SampleIDs = df['OTU ID'].to_list()\n",
    "        SampleIDs = [x.replace(\"-\",\"_\") for x in SampleIDs]\n",
    "\n",
    "        properties_df[group_name] = properties_df['SampleID'].apply(lambda x: 1 if x in SampleIDs else 0)\n",
    "\n",
    "        # Sanity check\n",
    "        if properties_df[properties_df[group_name] == 1].shape[0] != len(SampleIDs):\n",
    "            print(f\"Error: {group_name} sampleIDs do not match\")\n",
    "    else:\n",
    "        properties_df[group_name] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save name of samples\n",
    "with open(f\"{results_folder}/group_names/pathogen_group_names_{data_set}_data.txt\", \"w\") as file:\n",
    "    for group_name in all_group_names:\n",
    "        file.write(f\"{group_name}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save environmental properties data with labels\n",
    "properties_df.to_csv(f\"{data_folder}/DroughtITS_mapping_w_labels_{data_set}_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary for number of samples\n",
    "- number of smaples for each class for each pathogen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_name_sizes = []\n",
    "for group_name in all_group_names:\n",
    "    n_class0 = properties_df[properties_df[group_name] == 0].shape[0]\n",
    "    n_class1 = properties_df[properties_df[group_name] == 1].shape[0]\n",
    "    group_name_sizes.append({\n",
    "        \"name\": group_name,\n",
    "        \"class_0\": n_class0,\n",
    "        \"class_1\": n_class1\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_name_sizes_df = pd.DataFrame(group_name_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_name_sizes_df.to_csv(f\"{results_folder}/n_class_samples_per_pathogen_{data_set}_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crossplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features = ['lat', 'lon', 'drought',\n",
    "                      'water_content', 'organic_matter', \n",
    "                      'nitrogen', 'phosphorus', 'potassium',\n",
    "                      'temp_soil', 'pH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for group_name in all_group_names:\n",
    "    # Count the number of samples for class 0 and 1\n",
    "    class_counts = properties_df[group_name].value_counts()\n",
    "    class_0_count = class_counts.get(0, 0)  # Default to 0 if class 0 is not present\n",
    "    class_1_count = class_counts.get(1, 0)  # Default to 0 if class 1 is not present\n",
    "\n",
    "    # Create the pairplot\n",
    "    pairplot = sns.pairplot(properties_df[numerical_features + [group_name]], hue=group_name, palette='husl')\n",
    "\n",
    "    # Add a title with group_name and sample counts\n",
    "    pairplot.fig.suptitle(f\"{group_name} (Class 0: {class_0_count}, Class 1: {class_1_count})\", \n",
    "                          y=1.02)  # Adjust y to position the title above the plot\n",
    "\n",
    "    # Save the plot to a file\n",
    "    pairplot.savefig(f\"{cross_plots_folder}/{group_name}_pairplot_{data_set}_data.png\")\n",
    "\n",
    "    # Close the plot to free memory\n",
    "    plt.close(pairplot.fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boxplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for group_name in all_group_names:\n",
    "    # Separate features and label\n",
    "    label_column = group_name  # Replace with the actual name of your label column\n",
    "    # features = numerical_features\n",
    "    features =  ['drought',\n",
    "                        'water_content', 'organic_matter', \n",
    "                        'nitrogen', 'phosphorus', 'potassium',\n",
    "                        'temp_soil', 'pH']\n",
    "    y_labels = ['Drought Level', 'Water Content', 'Organic Matter', 'Nitrogen', 'Phosphorus', 'Potassium', 'Soil Temperature', 'Soil pH']\n",
    "\n",
    "    # Create subplots\n",
    "    fig, axes = plt.subplots(4, 2, figsize=(15, 16))  # 4 rows, 2 columns\n",
    "    axes = axes.flatten()  # Flatten to 1D array for easy indexing\n",
    "\n",
    "    # Define colors for the classes\n",
    "    palette = {'0': 'blue', '1': 'green'}\n",
    "\n",
    "    # Loop through each feature and create a subplot\n",
    "    for i, feature in enumerate(features):\n",
    "        sns.boxplot(data=properties_df, x=label_column, y=feature, ax=axes[i], hue = label_column, legend = False)\n",
    "        axes[i].set_title(f'Box Plot of {y_labels[i]}')\n",
    "        axes[i].set_xlabel('Class')\n",
    "        # axes[i].set_ylabel(feature)\n",
    "        axes[i].set_ylabel(y_labels[i])\n",
    "\n",
    "    class_counts = properties_df[group_name].value_counts()\n",
    "    class_0_count = class_counts.get(0, 0)  # Default to 0 if class 0 is not present\n",
    "    class_1_count = class_counts.get(1, 0)  # Default to 0 if class 1 is not present\n",
    "\n",
    "    # Add a title for the entire figure\n",
    "    fig.suptitle(f'Box Plots for {group_name} (Class 0: {class_0_count}, Class 1: {class_1_count})', fontsize=16)\n",
    "\n",
    "    # Adjust layout and leave space for the title\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.96])  # Adjust rect to leave space for the suptitle\n",
    "\n",
    "    # Save the figure to a file\n",
    "    output_path = f\"{box_plots_folder}/{group_name}_boxplot_{data_set}_data.png\"\n",
    "    plt.savefig(output_path)\n",
    "    plt.close(fig)  # Close the figure to free memory\n",
    "\n",
    "    print(f\"Saved box plot for {group_name} to {output_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
